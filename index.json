[{"categories":["开发"],"content":"# 1. 环境准备 首先是 rpmbuild 的相关依赖，无论是什么语言写的程序，只要是打包成 rpm 包，就都需要这些 yum install -y gcc make rpm-build redhat-rpm-config rpmbuild 的使用，需要你写不少的配置，非常繁琐，有研究过的人自然知道其中的泪。 但大多数情况下，一个简单的 rpm 包可能就只是执行一个二进制文件而已，完全没有去花费大量的时间去系统学习它们。 于是乎，有人就编写了一个开源工具 go-bin-rpm，用它可以很方便的将二进制文件打包成 rpm 包。 go-bin-rpm 的作者提供了多种安装方式 个人认为比较方便的是下面这条命令 wget -O - https://raw.githubusercontent.com/mh-cbon/latest/master/bintray.sh \\ | GH=mh-cbon/go-bin-rpm sh -xe 执行完成后，可以使用 --version 命令查看是否安装成功 $ go-bin-rpm --version go-bin-rpm version 1.0.0 ","date":"2022-11-11","objectID":"/posts/%E6%89%93%E6%88%90rpm%E5%8C%85/:1:0","tags":["rpm","build"],"title":"go程序打成rpm包","uri":"/posts/%E6%89%93%E6%88%90rpm%E5%8C%85/"},{"categories":["开发"],"content":"# 2. 配置文件 go-bin-rpm 的配置文件是 rpm.json ，当然你也可以用其他文件名，我这里直接使用默认的，这样后面打包时就不用指定配置文件的名字。 rpm.json 的内容相当精简，且直观易懂，模板如下 { \"name\": \"you-service-name\", # rpm 包名称 \"version\": \"0.0.1\", \"release\": \"20221110\", \"arch\": \"x86_64\", \"summary\": \"\", \"description\": \"\", \"license\": \"iswbm.com\", \"url\": \"https://gtihub.com/iswbm/!name!\", # !name! 相当于变量，会取前面 rpm 包名称 \"files\": [ { \"from\": \"./bin/!name!\", \"to\": \"/usr/local/!name!/\", \"base\": \"\", \"type\": \"\" }, { \"from\": \"./!name!.service\", \"to\": \"/usr/lib/systemd/system/\", \"base\": \"\", \"type\": \"\" } ] } 如果你的 rpm 安装后是以 service 运行的，那 files 要包含如下几项内容： 二进制文件 service 文件 配置文件（如果需要的话） 其中 service 文件的模板，这边也给出来 [Unit] Description= After=syslog.target network.target [Service] Environment=key=value Type=simple NotifyAccess=all TimeoutStartSec=0 Restart=always User=root ExecStart=/usr/local/xxxx/bin/xxxx [Install] WantedBy=multi-user.target 一切准备好了，就可以使用如下命令 # VERSION 和 RELEASE 请对应替换 go-bin-rpm generate -o rpms/xxxx-$(VERSION)-$(RELEASE).rpm 如果在不同的平台或系统有不同的二进制，则可以准备多个 rpm.json，然后在打包时，使用 -f rpm.json 来指定配置文件。 ","date":"2022-11-11","objectID":"/posts/%E6%89%93%E6%88%90rpm%E5%8C%85/:2:0","tags":["rpm","build"],"title":"go程序打成rpm包","uri":"/posts/%E6%89%93%E6%88%90rpm%E5%8C%85/"},{"categories":["开发"],"content":"# 3. 使用 Makefile go-bin-rpm 的命令还是比较长，我习惯写一个 Makefile 来方便编译 VERSION = 1.0.0 RELEASE = $(shell date +\"%Y%m%d\") .PHONY: build-go build-go: go build -o ./bin/hello . .PHONY: build build: build-go sed -i \"s/VERSION/$(VERSION)/g\" rpm.json sed -i \"s/RELEASE/$(RELEASE)/g\" rpm.json mkdir -p rpms go-bin-rpm generate -o rpms/hellp-$(VERSION)-$(RELEASE).rpm 后面只要使用 make build 就可以直接一步实现 编译 + 打包 ，使用上更加顺手。 ","date":"2022-11-11","objectID":"/posts/%E6%89%93%E6%88%90rpm%E5%8C%85/:3:0","tags":["rpm","build"],"title":"go程序打成rpm包","uri":"/posts/%E6%89%93%E6%88%90rpm%E5%8C%85/"},{"categories":[""],"content":"背景 是这样的，最近在研究一个定时任务系统的改造，可能有点像jenkins做到的那种吧。 可以输入shell命令，也可以执行py脚本等等，相比之前来说，也要能够及时停止！ 但是遇到了这么个问题，golang执行py脚本的时候获取不到脚本的输出。 1首先来看看go里面怎么运行shell脚本吧，我比较喜欢执行全部命令。 ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:0:0","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":[""],"content":"普通用法（一次性获取所有输出） package main import ( \"fmt\" \"os/exec\" ) func main() { Command(\"ls\") } // 这里为了简化，我省去了stderr和其他信息 func Command(cmd string) error { c := exec.Command(\"bash\", \"-c\", cmd) // 此处是windows版本 // c := exec.Command(\"cmd\", \"/C\", cmd) output, err := c.CombinedOutput() fmt.Println(string(output)) return err } 可以看到，当前命令执行的是输出当前目录下的文件/文件夹 实时显示 效果图: package main import ( \"bufio\" \"fmt\" \"io\" \"os/exec\" \"sync\" ) func main() { // 执行ping baidu的命令, 命令不会结束 Command(\"ping www.baidu.com\") } func Command(cmd string) error { //c := exec.Command(\"cmd\", \"/C\", cmd) // windows c := exec.Command(\"bash\", \"-c\", cmd) // mac or linux stdout, err := c.StdoutPipe() if err != nil { return err } var wg sync.WaitGroup wg.Add(1) go func() { defer wg.Done() reader := bufio.NewReader(stdout) for { readString, err := reader.ReadString('\\n') if err != nil || err == io.EOF { return } fmt.Print(readString) } }() err = c.Start() wg.Wait() return err } ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:0:1","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":[""],"content":"可关闭+实时输出 package main import ( \"bufio\" \"context\" \"fmt\" \"io\" \"os/exec\" \"sync\" \"time\" ) func main() { ctx, cancel := context.WithCancel(context.Background()) go func(cancelFunc context.CancelFunc) { time.Sleep(3 * time.Second) cancelFunc() }(cancel) Command(ctx, \"ping www.baidu.com\") } func Command(ctx context.Context, cmd string) error { // c := exec.CommandContext(ctx, \"cmd\", \"/C\", cmd) c := exec.CommandContext(ctx, \"bash\", \"-c\", cmd) // mac linux stdout, err := c.StdoutPipe() if err != nil { return err } var wg sync.WaitGroup wg.Add(1) go func(wg *sync.WaitGroup) { defer wg.Done() reader := bufio.NewReader(stdout) for { // 其实这段去掉程序也会正常运行，只是我们就不知道到底什么时候Command被停止了，而且如果我们需要实时给web端展示输出的话，这里可以作为依据 取消展示 select { // 检测到ctx.Done()之后停止读取 case \u003c-ctx.Done(): if ctx.Err() != nil { fmt.Printf(\"程序出现错误: %q\", ctx.Err()) } else { fmt.Println(\"程序被终止\") } return default: readString, err := reader.ReadString('\\n') if err != nil || err == io.EOF { return } fmt.Print(readString) } } }(\u0026wg) err = c.Start() wg.Wait() return err } 效果图: 可以看到输出了3次（1秒1次）之后程序就被终止了，确切的说是读取输出流的循环结束了。 ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:0:2","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":[""],"content":"执行Python脚本(阻塞) 其实很简单，只要python -u xxx.py这样执行就可以了, -u参数 简单的说就是python的输出是有缓存的，-u会强制往标准流输出，当Python脚本阻塞的时候 也不会拿不到输出！ ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:0:3","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":[""],"content":"其他 “bash” 和\"-c\"，据我的观察，这2个参数代表在当前cmd窗口执行，而不加这2个参数，直接上shell的话，会启动一个新窗口，目前观察是stdout拿不到数据。 ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:0:4","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":[""],"content":"仍有缺陷 上面的命令可以解决大部分问题，但是获取不到stderr的信息，所以我们需要改造一下。 下面是输出和错误一并输出的实时读取，类似于jenkins那种。 package main import ( \"bufio\" \"context\" \"fmt\" \"io\" \"os/exec\" \"sync\" \"time\" ) func main() { ctx, cancel := context.WithCancel(context.Background()) go func(cancelFunc context.CancelFunc) { time.Sleep(3 * time.Second) cancelFunc() }(cancel) Command(ctx, \"ping www.baidu.com\") } func read(ctx context.Context, wg *sync.WaitGroup, std io.ReadCloser) { reader := bufio.NewReader(std) defer wg.Done() for { select { case \u003c-ctx.Done(): return default: readString, err := reader.ReadString('\\n') if err != nil || err == io.EOF { return } fmt.Print(readString) } } } func Command(ctx context.Context, cmd string) error { //c := exec.CommandContext(ctx, \"cmd\", \"/C\", cmd) // windows c := exec.CommandContext(ctx, \"bash\", \"-c\", cmd) // mac linux stdout, err := c.StdoutPipe() if err != nil { return err } stderr, err := c.StderrPipe() if err != nil { return err } var wg sync.WaitGroup // 因为有2个任务, 一个需要读取stderr 另一个需要读取stdout wg.Add(2) go read(ctx, \u0026wg, stderr) go read(ctx, \u0026wg, stdout) // 这里一定要用start,而不是run 详情请看下面的图 err = c.Start() // 等待任务结束 wg.Wait() return err } ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:0:5","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":[""],"content":"windows输出乱码问题 参考资料： https://blog.csdn.net/rznice/article/details/88122923 最后给一个解决windows乱码的完整案例 需要下载golang.org/x/text/encoding/simplifiedchinese package main import ( \"bufio\" \"fmt\" \"io\" \"os/exec\" \"sync\" \"golang.org/x/text/encoding/simplifiedchinese\" ) type Charset string const ( UTF8 = Charset(\"UTF-8\") GB18030 = Charset(\"GB18030\") ) func main() { // 执行ping baidu的命令, 命令不会结束 Command(\"ping www.baidu.com\") } func Command(cmd string) error { //c := exec.Command(\"cmd\", \"/C\", cmd) // windows c := exec.Command(\"bash\", \"-c\", cmd) // mac or linux stdout, err := c.StdoutPipe() if err != nil { return err } var wg sync.WaitGroup wg.Add(1) go func() { defer wg.Done() reader := bufio.NewReader(stdout) for { readString, err := reader.ReadString('\\n') if err != nil || err == io.EOF { return } byte2String := ConvertByte2String([]byte(readString), \"GB18030\") fmt.Print(byte2String) } }() err = c.Start() wg.Wait() return err } func ConvertByte2String(byte []byte, charset Charset) string { var str string switch charset { case GB18030: var decodeBytes, _ = simplifiedchinese.GB18030.NewDecoder().Bytes(byte) str = string(decodeBytes) case UTF8: fallthrough default: str = string(byte) } return str } ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:0:6","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":[""],"content":"概述 远程执行命令有什么用？为什么要远程执行命令？ 如果你只有2，3台服务器需要管理的时候，远程执行命令确实没有没多大作用，你可以登录到每台服务器上去完成各种操作。 当你的服务器大于3台的时候，远程执行的命令的方式就可以大大提高你的生产力了。 如果你有一个可以远程执行命令的工具，那么就可以像操作单台机器那样操作多台机器，机器越多，效率提高的越多。 远程执行命令最常用的方法就是利用 SSH 协议，将命令发送到远程机器上执行，并获取返回结果。 本文介绍如何使用 golang 实现远程执行命令。 ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:1:0","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":[""],"content":"一般命令 所谓一般命令，就是在一定时间内会执行完的命令。比如 grep, cat 等等。 执行命令的步骤是：连接，执行，获取结果 ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:2:0","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":[""],"content":"连接 连接包含了认证，可以使用 password 或者 sshkey 2种方式来认证。下面的示例为了简单，使用了密码认证的方式来完成连接。 import ( \"fmt\" \"time\" \"golang.org/x/crypto/ssh\" ) func connect(user, password, host string, port int) (*ssh.Session, error) { var ( auth []ssh.AuthMethod addr string clientConfig *ssh.ClientConfig client *ssh.Client session *ssh.Session err error ) // get auth method auth = make([]ssh.AuthMethod, 0) auth = append(auth, ssh.Password(password)) clientConfig = \u0026ssh.ClientConfig{ User: user, Auth: auth, Timeout: 30 * time.Second, } // connet to ssh addr = fmt.Sprintf(\"%s:%d\", host, port) if client, err = ssh.Dial(\"tcp\", addr, clientConfig); err != nil { return nil, err } // create session if session, err = client.NewSession(); err != nil { return nil, err } return session, nil } 连接的方法很简单，只要提供登录主机的 用户*， *密码*， *主机名或者IP*， *SSH端口 ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:2:1","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":[""],"content":"执行，命令获取结果 连接成功后，执行命令很简单 import ( \"fmt\" \"log\" \"os\" \"time\" \"golang.org/x/crypto/ssh\" ) func main() { session, err := connect(\"root\", \"xxxxx\", \"127.0.0.1\", 22) if err != nil { log.Fatal(err) } defer session.Close() session.Run(\"ls /; ls /abc\") } 上面代码运行之后，虽然命令正常执行了，但是没有正常输出的结果，也没有异常输出的结果。 要想显示结果，需要将 session 的 Stdout 和 Stderr 重定向 修改 func main 为如下： func main() { session, err := connect(\"root\", \"xxxxx\", \"127.0.0.1\", 22) if err != nil { log.Fatal(err) } defer session.Close() session.Stdout = os.Stdout session.Stderr = os.Stderr session.Run(\"ls /; ls /abc\") } 这样就能在屏幕上显示正常，异常的信息了。 ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:2:2","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":[""],"content":"交互式命令 上面的方式无法远程执行交互式命令，比如 top ， 远程编辑一个文件，比如 vi /etc/nginx/nginx.conf 如果要支持交互式的命令，需要当前的terminal来接管远程的 PTY。 func main() { session, err := connect(\"root\", \"olordjesus\", \"dockers.iotalabs.io\", 2210) if err != nil { log.Fatal(err) } defer session.Close() fd := int(os.Stdin.Fd()) oldState, err := terminal.MakeRaw(fd) if err != nil { panic(err) } defer terminal.Restore(fd, oldState) // excute command session.Stdout = os.Stdout session.Stderr = os.Stderr session.Stdin = os.Stdin termWidth, termHeight, err := terminal.GetSize(fd) if err != nil { panic(err) } // Set up terminal modes modes := ssh.TerminalModes{ ssh.ECHO: 1, // enable echoing ssh.TTY_OP_ISPEED: 14400, // input speed = 14.4kbaud ssh.TTY_OP_OSPEED: 14400, // output speed = 14.4kbaud } // Request pseudo terminal if err := session.RequestPty(\"xterm-256color\", termHeight, termWidth, modes); err != nil { log.Fatal(err) } session.Run(\"top\") } 这样就可以执行交互式命令了，比如上面的 top 也可以通过 vi /etc/nginx/nignx.conf 之类的命令来远程编辑文件。 ","date":"2022-11-01","objectID":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/:3:0","tags":[""],"title":"go执行shell命令","uri":"/posts/go%E6%89%A7%E8%A1%8Cshell%E5%91%BD%E4%BB%A4/"},{"categories":["开发"],"content":"一、为什么使用context ","date":"2022-10-28","objectID":"/posts/go-context/:1:0","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"（1）go的扛把子 要论go最津津乐道的功能莫过于go强大而简洁的并发能力。 func main() { go func() { fmt.Println(\"Hello World\") }() } 通过简单的go func(){}，go可以快速生成新的协程并运行。 ","date":"2022-10-28","objectID":"/posts/go-context/:1:1","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"（2）想象一个没有context的世界 go里面常用于协程间通信和管理的有channel和sync包。比如channel可以通知协程做特定操作（退出，阻塞等），sync可以加锁和同步。 假如我要实现一个可以同时关闭所有协程的程序，可以这样实现。 package main import ( \"fmt\" \"sync\" ) func main() { // 通过一个chan来控制goroutine的执行 closed := make(chan struct{}) wg := sync.WaitGroup{} for i := 0; i \u003c 200; i++ { wg.Add(1) // do something go func(i int, wg *sync.WaitGroup) { select { case \u003c-closed: fmt.Printf(\"%d Closed\\n\", i) wg.Done() } }(i, \u0026wg) } // 发送指令关闭所有协程 close(closed) wg.Wait() } 因为go的协程不支持直接从外部退出，不像C++和Java有个线程ID可以操作。所以只能通过协程自己退出的方式。一般来说通过channel来控制是最方便的。 如果我想加点功能，比如到时间后退出，只要给channel增加关闭条件即可。 package main import ( \"fmt\" \"sync\" \"time\" ) func main() { // 通过一个chan来控制goroutine的执行 closed := make(chan struct{}) wg := sync.WaitGroup{} for i := 0; i \u003c 200; i++ { wg.Add(1) // do something go func(i int, wg *sync.WaitGroup) { select { case \u003c-closed: fmt.Printf(\"%d Closed\\n\", i) wg.Done() } }(i, \u0026wg) } // 加个时间条件 ta := time.After(5 * time.Second) select { case \u003c-ta: close(closed) } wg.Wait() } ","date":"2022-10-28","objectID":"/posts/go-context/:1:2","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"（3）用context精简代码 上面的代码已经够简单了，但是还是显得有些复杂。比如每次都要在协程内部增加对channel的判断，也要在外部设置关闭条件。试想一下，如果程序要限制的是总时长，而不是单个操作的时长，这样每个操作要限制多少时间也是个难题。 这个时候就轮到context登场了。context顾名思义是协程的上下文，主要用于跟踪协程的状态，可以做一些简单的协程控制，也能记录一些协程信息。 下面试着用context改造下前面的例子： package main import ( \"context\" \"fmt\" \"sync\" \"time\" ) func main() { // 空的父context parentCtx := context.Background() // 子context（携带有超时信息），cancel函数（可以主动触发取消） //ctx, cancel := context.WithTimeout(parentCtx, 5*time.Second) ctx, _ := context.WithTimeout(parentCtx, 5*time.Second) wg := sync.WaitGroup{} for i := 0; i \u003c 2; i++ { wg.Add(1) go func(i int) { defer wg.Done() // do something // 大部分工具库内置了对ctx的判断，下面的部分几乎可以省略 select { case \u003c-ctx.Done(): fmt.Printf(\"%d Done\\n\", i) } }(i) } // 调用cancel会直接关闭ctx.Done()返回的管道，不用等到超时 //cancel() wg.Wait() } 通过context可以进一步简化控制代码，且更为友好的是，大多数go库，如http、各种db driver、grpc等都内置了对ctx.Done()的判断，我们只需要将ctx传入即可。 ","date":"2022-10-28","objectID":"/posts/go-context/:1:3","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"二、context基础用法 接下来介绍context的基础用法，最为重要的就是3个基础能力，取消、超时、附加值。 ","date":"2022-10-28","objectID":"/posts/go-context/:2:0","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"（1）新建一个context ctx := context.TODO() ctx := context.Background() 这两个方法返回的内容是一样的，都是返回一个空的context，这个context一般用来做父context。 ","date":"2022-10-28","objectID":"/posts/go-context/:2:1","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"（2）WithCancel // 函数声明 func WithCancel(parent context) (ctx context, cancel CancelFunc) // 用法:返回一个子Context和主动取消函数 ctx, cancel := context.WithCancel(parentCtx) 这个函数相当重要，会根据传入的context生成一个子context和一个取消函数。当父context有相关取消操作，或者直接调用cancel函数的话，子context就会被取消。 举个日常业务中常用的例子： // 一般操作比较耗时或者涉及远程调用等，都会在输入参数里带上一个ctx，这也是公司代码规范里提倡的 func Do(ctx context.Context, ...) { ctx, cancel := context.WithCancel(parentCtx) // 实现某些业务逻辑 // 当遇到某种条件，比如程序出错，就取消掉子Context，这样子Context绑定的协程也可以跟着退出 if err != nil { cancel() } } ","date":"2022-10-28","objectID":"/posts/go-context/:2:2","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"（3）WithTimeout // 函数声明 func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) // 用法：返回一个子Context（会在一段时间后自动取消），主动取消函数 ctx := context.WithTimeout(parentCtx, 5*time.Second) 这个函数在日常工作中使用得非常多，简单来说就是给context附加一个超时控制，当超时ctx.Done()返回的channel就能读取到值，协程可以通过这个方式来判断执行时间是否满足要求。 举个日常业务中常用的例子： // 一般操作比较耗时或者涉及远程调用等，都会在输入参数里带上一个ctx，这也是公司代码规范里提倡的 func Do(ctx context.Context, ...) { ctx, cancel := context.WithTimeout(parentCtx) // 实现某些业务逻辑 for { select { // 轮询检测是否已经超时 case \u003c-ctx.Done(): return // 有时也会附加一些错误判断 case \u003c-errCh: cancel() default: } } } 现在大部分go库都实现了超时判断逻辑，我们只需要传入ctx就好。 ","date":"2022-10-28","objectID":"/posts/go-context/:2:3","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"（4）WithDeadline // 函数声明 func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) // 用法：返回一个子Context（会在指定的时间自动取消），主动取消函数 ctx, cancel := context.WithDeadline(parentCtx, time.Now().Add(5*time.Second)) 这个函数感觉用得比较少，和WithTimeout相比的话就是使用的是截止时间。 ","date":"2022-10-28","objectID":"/posts/go-context/:2:4","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"（5）WithValue // 函数声明 func WithValue(parent Context, key, val interface{}) Context // 用法: 传入父Context和(key, value)，相当于存一个kv ctx := context.WithValue(parentCtx, \"name\", 123) // 用法：将key对应的值取出 v := ctx.Value(\"name\") 这个函数常用来保存一些链路追踪信息，比如API服务里会有来保存一些来源ip、请求参数等。 因为这个方法实在是太常用了，比如grpc-go里的metadata就使用这个方法将结构体存储在ctx里。 func NewOutgoingContext(ctx context.Context, md MD) context.Context { return context.WithValue(ctx, mdOutgoingKey{}, rawMD{md: md}) } ","date":"2022-10-28","objectID":"/posts/go-context/:2:5","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"三、context源码实现 ","date":"2022-10-28","objectID":"/posts/go-context/:3:0","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"（1）理解context Context是一个接口 虽然我们平时写代码时直接context.Context拿来就用，但实际上context.Context是一个接口，源码里是有多种不同的实现的，借此实现不同的功能。 type Context interface { // 返回这个ctx预期的结束时间 Deadline() (deadline time.Time, ok bool) // 返回一个channel，当执行结束或者取消时被close，我们平时可以用这个来判断ctx绑定的协程是否该退出。实现里用的懒汉模式，所以一开始可能会返回nil Done() \u003c-chan struct{} // 如果未完成，返回nil。已完成源码里目前就两种错误，已被取消或者已超时 Err() error // 返回ctx绑定的key对应的value值 Value(key interface{}) interface{} } context们是一棵树 context整体是一个树形结构，不同的ctx间可能是兄弟节点或者是父子节点的关系。 同时由于Context接口有多种不同的实现，所以树的节点可能也是多种不同的ctx实现。总的来说我觉得context的特点是： 树形结构，每次调用WithCancel, WithValue, WithTimeout, WithDeadline实际是为当前节点在追加子节点。 继承性，某个节点被取消，其对应的子树也会全部被取消。 多样性，节点存在不同的实现，故每个节点会附带不同的功能。 ​ context的果子们 在源码里实际只有4种实现，要弄懂context的源码其实把这4种对应的实现学习一下就行，他们分别是： emptyCtx：一个空的ctx，一般用于做根节点。 cancelCtx：核心，用来处理取消相关的操作。 timerCtx：用来处理超时相关操作。 valueCtx：附加值的实现方法。 现在先简单对这几个实现有个概念，后面会对其中核心关键的部分讲解下。 ","date":"2022-10-28","objectID":"/posts/go-context/:3:1","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"（2）context类图 从类图中可以看出，源码里有4种结构和3种接口，相对于其他go库源码来说是比较简单的。 核心的接口是Context，里面包含了最常用的判断是否处理完成的Done()方法 。其他所有结构都通过①实现方法或②组合的方式来实现该接口。 核心的结构是cancelCtx，被timerCtx包含。cancelCtx和timerCtx可以说代表了context库最核心的取消和超时相关的实现，也最为复杂些。 ","date":"2022-10-28","objectID":"/posts/go-context/:3:2","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"（3）context源码 因为篇幅关系，不会把每一行源码都拎出来，会挑比较重点的方法讲下。由于平时我们使用都是通过几个固定的方法入口，所以会围绕这几个方法讲下 emptyCtx 对外体现 var ( background = new(emptyCtx) todo = new(emptyCtx) ) func Background() Context { return background } func TODO() Context { return todo } TODO()，Background()其实都是返回一个emptyCtx。 实现 type emptyCtx int func (*emptyCtx) Deadline() (deadline time.Time, ok bool) { return } func (*emptyCtx) Done() \u003c-chan struct{} { return nil } func (*emptyCtx) Err() error { return nil } func (*emptyCtx) Value(key interface{}) interface{} { return nil } func (e *emptyCtx) String() string { switch e { case background: return \"context.Background\" case todo: return \"context.TODO\" } return \"unknown empty Context\" } 这个结构非常简单，都是返回nil。emptyCtx主要用于新建一个独立的树。比方说，我想在协程里做些异步操作，但是又想脱离主协程的ctx控制如使用独立的超时限制，就可以使用这种方式。但是在整个go程序里只有todo和background两个大根节点，所以TODO()和Background()其实是新建第二层级的子树。 func demo(ctx context.Context){ nctx := context.TODO() nctx := context.WithTimeout(nctx, 5*time.Second) ... } valueCtx 对外体现 // 设置key, value值 func WithValue(parent Context, key, val interface{}) Context { if key == nil { panic(\"nil key\") } if !reflectlite.TypeOf(key).Comparable() { panic(\"key is not comparable\") } // 在当前节点下生成新的子节点 return \u0026valueCtx{parent, key, val} } // 根据key读取value func (c *valueCtx) Value(key interface{}) interface{} { if c.key == key { return c.val } return c.Context.Value(key) } 通过公共方法设置值，再通过valueCtx的内部方法获取值。后面再仔细讲下Value的实现方式。 实现 type valueCtx struct { Context key, val interface{} } // 根据key读取value func (c *valueCtx) Value(key interface{}) interface{} { // 每个ctx只绑定一个key，匹配则返回。否则向上追溯到匹配为止 if c.key == key { return c.val } return c.Context.Value(key) } 从实现上可以看出，每当我们往ctx里调WithValue塞值时，都会生成一个新的子节点。调用的次数多了，生成的子树就很庞大。 若当前节点的key和传入的key不匹配会沿着继承关系向上递归查找。递归到根就变成nil，表示当前key在该子树序列里没存。 cancelCtx 介绍完上面两种比较简单的结构后，终于要来到复杂的cancelCtx。cancelCtx和timerCtx关联性很强，基本上弄懂一个，另外一个也差不多了。 对外方法 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { // 新建一个cancelCtx c := newCancelCtx(parent) // 将父节点的取消函数和子节点关联，做到父节点取消，子节点也跟着取消 propagateCancel(parent, \u0026c) // 返回当前节点和主动取消函数（调用会将自身从父节点移除，并返回一个已取消错误） return \u0026c, func() { c.cancel(true, Canceled) } } 对外的方法里包含的几个方法都是重点的方法，后面主要讲下 结构 type cancelCtx struct { Context mu sync.Mutex // protects following fields done chan struct{} // created lazily, closed by first cancel call children map[canceler]struct{} // set to nil by the first cancel call err error // set to non-nil by the first cancel call } done：用于判断是否完成。 cancel：存子取消节点。 err：取消时的错误，超时或主动取消。 type canceler interface { cancel(removeFromParent bool, err error) Done() \u003c-chan struct{} } 这个接口约定了可以取消的context，比如cancelCtx和timerCtx是可以取消的，emptyCtx和valueCtx是不可以取消的。 初始化 // newCancelCtx returns an initialized cancelCtx. func newCancelCtx(parent Context) cancelCtx { return cancelCtx{Context: parent} } 初始化就是将父节点设置了一下，其他不设置。 cancelCtx的取消实现 // cancel closes c.done, cancels each of c's children, and, if // removeFromParent is true, removes c from its parent's children. func (c *cancelCtx) cancel(removeFromParent bool, err error) { // 取消无论是通过父节点还是自身主动取消，err都不为空 if err == nil { panic(\"context: internal error: missing cancel error\") } c.mu.Lock() if c.err != nil { // c.err 不为空表示已经被取消过，比如父节点取消时子节点可能已经主动调用过取消函数 c.mu.Unlock() return // already canceled } c.err = err if c.done == nil { // closedchan 是一个已经关闭的channel，要特殊处理是因为c.done是懒加载的方式。只有调用c.Done()时才会实际创建 c.done = closedchan } else { close(c.done) } // 递归取消子节点 for child := range c.children { // NOTE: acquiring the child's lock while holding parent's lock. child.cancel(false, err) } c.children = nil c.mu.Unlock() // 从父节点中移除当前节点 if removeFromParent { removeChild(c.Context, c) } } 整个过程可以总结为： 前置判断，看是否为异常情况。 关闭c.done，这样外部调用cancelCtx.Done()就会有返回结果。 递归调用子节点的cancel方法。 视情况从父节点中移除子节点。 这里child.cancel(false，err)不从父节点移除子节点是因为当前节点操作已取过锁，移除操作会再取锁造成冲突，故先全部cancel后再将children置为nil一次性移除。 propagateCancel 绑定父子节点的取消关系 // propagateCancel arranges for child to be canceled when parent is. func propagateCancel(parent Context, child canceler) { done := parent.Done() if done == nil { // 若当前节点追溯到根没有cancelCtx或","date":"2022-10-28","objectID":"/posts/go-context/:3:3","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"四、总结 综上所述，context的主要功能就是用于控制协程退出和附加链路信息。核心实现的结构体有4个，最复杂的是cancelCtx，最常用的是cancelCtx和valueCtx。整体呈树状结构，父子节点间同步取消信号。 ","date":"2022-10-28","objectID":"/posts/go-context/:4:0","tags":["context"],"title":"go context","uri":"/posts/go-context/"},{"categories":["开发"],"content":"grpc实战：pc book","date":"2022-10-26","objectID":"/posts/grpc/","tags":["grpc"],"title":"grpc","uri":"/posts/grpc/"},{"categories":["开发"],"content":"初始化项目 新建相关文件夹 mkdir -p pc-book/{proto,pb} # proto 用于存放protobuf文件 # pb用于存放生成好的go代码 最终目录结构如下 . ├── README ├── go.mod ├── go.sum ├── main.go ├── pb └── proto ","date":"2022-10-26","objectID":"/posts/grpc/:1:0","tags":["grpc"],"title":"grpc","uri":"/posts/grpc/"},{"categories":["开发"],"content":"编写proto文件 在proto文件夹下新建processor_message.proto syntax = 'proto3'; // 需要加入下面的一行， // option go_package = \"path;name\" // path 表示生成的go文件的存放地址 // name 表示生成的go文件所属的包名 option go_package = \"./;pb\"; message CPU { string brand = 1; string name = 2; uint32 number_cores = 3; uint32 number_threads = 4; double min_ghz = 5; double max_ghz = 6; } ","date":"2022-10-26","objectID":"/posts/grpc/:2:0","tags":["grpc"],"title":"grpc","uri":"/posts/grpc/"},{"categories":["开发"],"content":"配置grpc自动生成 ","date":"2022-10-26","objectID":"/posts/grpc/:3:0","tags":["grpc"],"title":"grpc","uri":"/posts/grpc/"},{"categories":["开发"],"content":"1. 安装protoc 直接使用homebrew安装protoc brew install protobuf 安装完成后就可以直接使用protoc命令了 ","date":"2022-10-26","objectID":"/posts/grpc/:3:1","tags":["grpc"],"title":"grpc","uri":"/posts/grpc/"},{"categories":["开发"],"content":"2. 安装相关go-libraries go get -u google.golang.org/grpc go install github.com/golang/protobuf/protoc-gen-go ","date":"2022-10-26","objectID":"/posts/grpc/:3:2","tags":["grpc"],"title":"grpc","uri":"/posts/grpc/"},{"categories":["开发"],"content":"生成go代码 因为前面proto文件中已加入了option go_package = “path;name”，所以执行 protoc --proto_path=proto proto/*.proto --go_out=plugins=grpc:pb 即可在pb目录下生成对应的go代码：processor_message.pb.go –go_out：设置所生成 Go 代码输出的目录，该指令会加载 protoc-gen-go 插件达到生成 Go 代码的目的，生成的文件以 .pb.go 为文件后缀，在这里 “:”（冒号）号充当分隔符的作用，后跟命令所需要的参数集，在这里代表着要将所生成的 Go 代码输出到所指向 protoc 编译的当前目录。 plugins=plugin1+plugin2：指定要加载的子插件列表，我们定义的 proto 文件是涉及了 RPC 服务的，而默认是不会生成 RPC 代码的，因此需要在 go_out 中给出 plugins 参数传递给 protoc-gen-go，告诉编译器，请支持 RPC（这里指定了内置的 grpc 插件）。 –proto_path: 指定proto文件的路径 每次生成敲上面一串很麻烦，新建一个Makefile文件 gen: protoc --proto_path=proto proto/*.proto --go_out=plugins=grpc:pb clean: rm -fr pb/*.go run: go run main.go 后续直接执行make gen、make clean、make run即可 ","date":"2022-10-26","objectID":"/posts/grpc/:4:0","tags":["grpc"],"title":"grpc","uri":"/posts/grpc/"},{"categories":["开发"],"content":"在Go语言项目中使用Zap日志库","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"本文先介绍了Go语言原生的日志库的使用，然后详细介绍了非常流行的Uber开源的zap日志库，同时介绍了如何搭配Lumberjack实现日志的切割和归档。 在Go语言项目中使用Zap日志库 ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:0:0","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"介绍 在许多Go语言项目中，我们需要一个好的日志记录器能够提供下面这些功能： 能够将事件记录到文件中，而不是应用程序控制台。 日志切割-能够根据文件大小、时间或间隔等来切割日志文件。 支持不同的日志级别。例如INFO，DEBUG，ERROR等。 能够打印基本信息，如调用文件/函数名和行号，日志时间等。 ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:1:0","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"默认的Go Logger 在介绍Uber-go的zap包之前，让我们先看看Go语言提供的基本日志功能。Go语言提供的默认日志包是https://golang.org/pkg/log/ ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:2:0","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"实现Go Logger 实现一个Go语言中的日志记录器非常简单——创建一个新的日志文件，然后设置它为日志的输出位置。 设置Logger 我们可以像下面的代码一样设置日志记录器 func SetupLogger() { logFileLocation, _ := os.OpenFile(\"/Users/q1mi/test.log\", os.O_CREATE|os.O_APPEND|os.O_RDWR, 0744) log.SetOutput(logFileLocation) } 使用Logger 让我们来写一些虚拟的代码来使用这个日志记录器。 在当前的示例中，我们将建立一个到URL的HTTP连接，并将状态代码/错误记录到日志文件中。 func simpleHttpGet(url string) { resp, err := http.Get(url) if err != nil { log.Printf(\"Error fetching url %s : %s\", url, err.Error()) } else { log.Printf(\"Status Code for %s : %s\", url, resp.Status) resp.Body.Close() } } Logger的运行 现在让我们执行上面的代码并查看日志记录器的运行情况。 func main() { SetupLogger() simpleHttpGet(\"www.google.com\") simpleHttpGet(\"http://www.google.com\") } 当我们执行上面的代码，我们能看到一个test.log文件被创建，下面的内容会被添加到这个日志文件中。 2019/05/24 01:14:13 Error fetching url www.google.com : Get www.google.com: unsupported protocol scheme \"\" 2019/05/24 01:14:14 Status Code for http://www.google.com : 200 OK ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:2:1","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"Go Logger的优势和劣势 优势 它最大的优点是使用非常简单。我们可以设置任何io.Writer作为日志记录输出并向其发送要写入的日志。 劣势 仅限基本的日志级别 只有一个Print选项。不支持INFO/DEBUG等多个级别。 对于错误日志，它有Fatal和Panic Fatal日志通过调用os.Exit(1)来结束程序 Panic日志在写入日志消息之后抛出一个panic 但是它缺少一个ERROR日志级别，这个级别可以在不抛出panic或退出程序的情况下记录错误 缺乏日志格式化的能力——例如记录调用者的函数名和行号，格式化日期和时间格式。等等。 不提供日志切割的能力。 ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:2:2","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"Uber-go Zap Zap是非常快的、结构化的，分日志级别的Go日志库。 ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:3:0","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"为什么选择Uber-go zap 它同时提供了结构化日志记录和printf风格的日志记录 它非常的快 根据Uber-go Zap的文档，它的性能比类似的结构化日志包更好——也比标准库更快。 以下是Zap发布的基准测试信息 记录一条消息和10个字段: Package Time Time % to zap Objects Allocated ⚡️ zap 862 ns/op +0% 5 allocs/op ⚡️ zap (sugared) 1250 ns/op +45% 11 allocs/op zerolog 4021 ns/op +366% 76 allocs/op go-kit 4542 ns/op +427% 105 allocs/op apex/log 26785 ns/op +3007% 115 allocs/op logrus 29501 ns/op +3322% 125 allocs/op log15 29906 ns/op +3369% 122 allocs/op 记录一个静态字符串，没有任何上下文或printf风格的模板： Package Time Time % to zap Objects Allocated ⚡️ zap 118 ns/op +0% 0 allocs/op ⚡️ zap (sugared) 191 ns/op +62% 2 allocs/op zerolog 93 ns/op -21% 0 allocs/op go-kit 280 ns/op +137% 11 allocs/op standard library 499 ns/op +323% 2 allocs/op apex/log 1990 ns/op +1586% 10 allocs/op logrus 3129 ns/op +2552% 24 allocs/op log15 3887 ns/op +3194% 23 allocs/op ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:3:1","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"安装 运行下面的命令安装zap go get -u go.uber.org/zap ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:3:2","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"配置Zap Logger Zap提供了两种类型的日志记录器—Sugared Logger和Logger。 在性能很好但不是很关键的上下文中，使用SugaredLogger。它比其他结构化日志记录包快4-10倍，并且支持结构化和printf风格的日志记录。 在每一微秒和每一次内存分配都很重要的上下文中，使用Logger。它甚至比SugaredLogger更快，内存分配次数也更少，但它只支持强类型的结构化日志记录。 Logger 通过调用zap.NewProduction()/zap.NewDevelopment()或者zap.Example()创建一个Logger。 上面的每一个函数都将创建一个logger。唯一的区别在于它将记录的信息不同。例如production logger默认记录调用函数信息、日期和时间等。 通过Logger调用Info/Error等。 默认情况下日志都会打印到应用程序的console界面。 var logger *zap.Logger func main() { InitLogger() defer logger.Sync() simpleHttpGet(\"www.google.com\") simpleHttpGet(\"http://www.google.com\") } func InitLogger() { logger, _ = zap.NewProduction() } func simpleHttpGet(url string) { resp, err := http.Get(url) if err != nil { logger.Error( \"Error fetching url..\", zap.String(\"url\", url), zap.Error(err)) } else { logger.Info(\"Success..\", zap.String(\"statusCode\", resp.Status), zap.String(\"url\", url)) resp.Body.Close() } } 在上面的代码中，我们首先创建了一个Logger，然后使用Info/ Error等Logger方法记录消息。 日志记录器方法的语法是这样的： func (log *Logger) MethodXXX(msg string, fields ...Field) 其中MethodXXX是一个可变参数函数，可以是Info / Error/ Debug / Panic等。每个方法都接受一个消息字符串和任意数量的zapcore.Field场参数。 每个zapcore.Field其实就是一组键值对参数。 我们执行上面的代码会得到如下输出结果： {\"level\":\"error\",\"ts\":1572159218.912792,\"caller\":\"zap_demo/temp.go:25\",\"msg\":\"Error fetching url..\",\"url\":\"www.sogo.com\",\"error\":\"Get www.sogo.com: unsupported protocol scheme \\\"\\\"\",\"stacktrace\":\"main.simpleHttpGet\\n\\t/Users/q1mi/zap_demo/temp.go:25\\nmain.main\\n\\t/Users/q1mi/zap_demo/temp.go:14\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\"} {\"level\":\"info\",\"ts\":1572159219.1227388,\"caller\":\"zap_demo/temp.go:30\",\"msg\":\"Success..\",\"statusCode\":\"200 OK\",\"url\":\"http://www.sogo.com\"} Sugared Logger 现在让我们使用Sugared Logger来实现相同的功能。 大部分的实现基本都相同。 惟一的区别是，我们通过调用主logger的. Sugar()方法来获取一个SugaredLogger。 然后使用SugaredLogger以printf格式记录语句 下面是修改过后使用SugaredLogger代替Logger的代码： var sugarLogger *zap.SugaredLogger func main() { InitLogger() defer sugarLogger.Sync() simpleHttpGet(\"www.google.com\") simpleHttpGet(\"http://www.google.com\") } func InitLogger() { logger, _ := zap.NewProduction() sugarLogger = logger.Sugar() } func simpleHttpGet(url string) { sugarLogger.Debugf(\"Trying to hit GET request for %s\", url) resp, err := http.Get(url) if err != nil { sugarLogger.Errorf(\"Error fetching URL %s : Error = %s\", url, err) } else { sugarLogger.Infof(\"Success! statusCode = %s for URL %s\", resp.Status, url) resp.Body.Close() } } 当你执行上面的代码会得到如下输出： {\"level\":\"error\",\"ts\":1572159149.923002,\"caller\":\"logic/temp2.go:27\",\"msg\":\"Error fetching URL www.sogo.com : Error = Get www.sogo.com: unsupported protocol scheme \\\"\\\"\",\"stacktrace\":\"main.simpleHttpGet\\n\\t/Users/q1mi/zap_demo/logic/temp2.go:27\\nmain.main\\n\\t/Users/q1mi/zap_demo/logic/temp2.go:14\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\"} {\"level\":\"info\",\"ts\":1572159150.192585,\"caller\":\"logic/temp2.go:29\",\"msg\":\"Success! statusCode = 200 OK for URL http://www.sogo.com\"} 你应该注意到的了，到目前为止这两个logger都打印输出JSON结构格式。 在本博客的后面部分，我们将更详细地讨论SugaredLogger，并了解如何进一步配置它。 ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:3:3","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"定制logger 将日志写入文件而不是终端 我们要做的第一个更改是把日志写入文件，而不是打印到应用程序控制台。 我们将使用zap.New(…)方法来手动传递所有配置，而不是使用像zap.NewProduction()这样的预置方法来创建logger。 func New(core zapcore.Core, options ...Option) *Logger zapcore.Core需要三个配置——Encoder，WriteSyncer，LogLevel。 1.Encoder:编码器(如何写入日志)。我们将使用开箱即用的NewJSONEncoder()，并使用预先设置的ProductionEncoderConfig()。 zapcore.NewJSONEncoder(zap.NewProductionEncoderConfig()) 2.WriterSyncer ：指定日志将写到哪里去。我们使用zapcore.AddSync()函数并且将打开的文件句柄传进去。 file, _ := os.Create(\"./test.log\") writeSyncer := zapcore.AddSync(file) 3.Log Level：哪种级别的日志将被写入。 我们将修改上述部分中的Logger代码，并重写InitLogger()方法。其余方法—main() /SimpleHttpGet()保持不变。 func InitLogger() { writeSyncer := getLogWriter() encoder := getEncoder() core := zapcore.NewCore(encoder, writeSyncer, zapcore.DebugLevel) logger := zap.New(core) sugarLogger = logger.Sugar() } func getEncoder() zapcore.Encoder { return zapcore.NewJSONEncoder(zap.NewProductionEncoderConfig()) } func getLogWriter() zapcore.WriteSyncer { file, _ := os.Create(\"./test.log\") return zapcore.AddSync(file) } 当使用这些修改过的logger配置调用上述部分的main()函数时，以下输出将打印在文件——test.log中。 {\"level\":\"debug\",\"ts\":1572160754.994731,\"msg\":\"Trying to hit GET request for www.sogo.com\"} {\"level\":\"error\",\"ts\":1572160754.994982,\"msg\":\"Error fetching URL www.sogo.com : Error = Get www.sogo.com: unsupported protocol scheme \\\"\\\"\"} {\"level\":\"debug\",\"ts\":1572160754.994996,\"msg\":\"Trying to hit GET request for http://www.sogo.com\"} {\"level\":\"info\",\"ts\":1572160757.3755069,\"msg\":\"Success! statusCode = 200 OK for URL http://www.sogo.com\"} 将JSON Encoder更改为普通的Log Encoder 现在，我们希望将编码器从JSON Encoder更改为普通Encoder。为此，我们需要将NewJSONEncoder()更改为NewConsoleEncoder()。 return zapcore.NewConsoleEncoder(zap.NewProductionEncoderConfig()) 当使用这些修改过的logger配置调用上述部分的main()函数时，以下输出将打印在文件——test.log中。 1.572161051846623e+09 debug Trying to hit GET request for www.sogo.com 1.572161051846828e+09 error Error fetching URL www.sogo.com : Error = Get www.sogo.com: unsupported protocol scheme \"\" 1.5721610518468401e+09 debug Trying to hit GET request for http://www.sogo.com 1.572161052068744e+09 info Success! statusCode = 200 OK for URL http://www.sogo.com 更改时间编码并添加调用者详细信息 鉴于我们对配置所做的更改，有下面两个问题： 时间是以非人类可读的方式展示，例如1.572161051846623e+09 调用方函数的详细信息没有显示在日志中 我们要做的第一件事是覆盖默认的ProductionConfig()，并进行以下更改: 修改时间编码器 在日志文件中使用大写字母记录日志级别 func getEncoder() zapcore.Encoder { encoderConfig := zap.NewProductionEncoderConfig() encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder return zapcore.NewConsoleEncoder(encoderConfig) } 接下来，我们将修改zap logger代码，添加将调用函数信息记录到日志中的功能。为此，我们将在zap.New(..)函数中添加一个Option。 logger := zap.New(core, zap.AddCaller()) 当使用这些修改过的logger配置调用上述部分的main()函数时，以下输出将打印在文件——test.log中。 2019-10-27T15:33:29.855+0800 DEBUG logic/temp2.go:47 Trying to hit GET request for www.sogo.com 2019-10-27T15:33:29.855+0800 ERROR logic/temp2.go:50 Error fetching URL www.sogo.com : Error = Get www.sogo.com: unsupported protocol scheme \"\" 2019-10-27T15:33:29.856+0800 DEBUG logic/temp2.go:47 Trying to hit GET request for http://www.sogo.com 2019-10-27T15:33:30.125+0800 INFO logic/temp2.go:52 Success! statusCode = 200 OK for URL http://www.sogo.com AddCallerSkip 当我们不是直接使用初始化好的logger实例记录日志，而是将其包装成一个函数等，此时日录日志的函数调用链会增加，想要获得准确的调用信息就需要通过AddCallerSkip函数来跳过。 logger := zap.New(core, zap.AddCaller(), zap.AddCallerSkip(1)) 将日志输出到多个位置 我们可以将日志同时输出到文件和终端。 func getLogWriter() zapcore.WriteSyncer { file, _ := os.Create(\"./test.log\") // 利用io.MultiWriter支持文件和终端两个输出目标 ws := io.MultiWriter(file, os.Stdout) return zapcore.AddSync(ws) } 将err日志单独输出到文件 有时候我们除了将全量日志输出到xx.log文件中之外，还希望将ERROR级别的日志单独输出到一个名为xx.err.log的日志文件中。我们可以通过以下方式实现。 func InitLogger() { encoder := getEncoder() // test.log记录全量日志 logF, _ := os.Create(\"./test.log\") c1 := zapcore.NewCore(encoder, zapcore.AddSync(logF), zapcore.DebugLevel) // test.err.log记录ERROR级别的日志 errF, _ := os.Create(\"./test.err.log\") c2 := zapcore.NewCore(encoder, zapcore.AddSync(errF), zap.ErrorLevel) // 使用NewTee将c1和c2合并到core core := zapcore.NewTee(c1, c2) logger = zap.New(core, zap.A","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:3:4","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"使用Lumberjack进行日志切割归档 这个日志程序中唯一缺少的就是日志切割归档功能。 Zap本身不支持切割归档日志文件 官方的说法是为了添加日志切割归档功能，我们将使用第三方库Lumberjack来实现。 目前只支持按文件大小切割，原因是按时间切割效率低且不能保证日志数据不被破坏。详情戳https://github.com/natefinch/lumberjack/issues/54。 想按日期切割可以使用github.com/lestrrat-go/file-rotatelogs这个库，虽然目前不维护了，但也够用了。 // 使用file-rotatelogs按天切割日志 import rotatelogs \"github.com/lestrrat-go/file-rotatelogs\" l, _ := rotatelogs.New( filename+\".%Y%m%d%H%M\", rotatelogs.WithMaxAge(30*24*time.Hour), // 最长保存30天 rotatelogs.WithRotationTime(time.Hour*24), // 24小时切割一次 ) zapcore.AddSync(l) ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:4:0","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"安装 执行下面的命令安装 Lumberjack v2 版本。 go get gopkg.in/natefinch/lumberjack.v2 ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:4:1","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"zap logger中加入Lumberjack 要在zap中加入Lumberjack支持，我们需要修改WriteSyncer代码。我们将按照下面的代码修改getLogWriter()函数： func getLogWriter() zapcore.WriteSyncer { lumberJackLogger := \u0026lumberjack.Logger{ Filename: \"./test.log\", MaxSize: 10, MaxBackups: 5, MaxAge: 30, Compress: false, } return zapcore.AddSync(lumberJackLogger) } Lumberjack Logger采用以下属性作为输入: Filename: 日志文件的位置 MaxSize：在进行切割之前，日志文件的最大大小（以MB为单位） MaxBackups：保留旧文件的最大个数 MaxAges：保留旧文件的最大天数 Compress：是否压缩/归档旧文件 ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:4:2","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["开发"],"content":"测试所有功能 最终，使用Zap/Lumberjack logger的完整示例代码如下： package main import ( \"net/http\" \"gopkg.in/natefinch/lumberjack.v2\" \"go.uber.org/zap\" \"go.uber.org/zap/zapcore\" ) var sugarLogger *zap.SugaredLogger func main() { InitLogger() defer sugarLogger.Sync() simpleHttpGet(\"www.sogo.com\") simpleHttpGet(\"http://www.sogo.com\") } func InitLogger() { writeSyncer := getLogWriter() encoder := getEncoder() core := zapcore.NewCore(encoder, writeSyncer, zapcore.DebugLevel) logger := zap.New(core, zap.AddCaller()) sugarLogger = logger.Sugar() } func getEncoder() zapcore.Encoder { encoderConfig := zap.NewProductionEncoderConfig() encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder return zapcore.NewConsoleEncoder(encoderConfig) } func getLogWriter() zapcore.WriteSyncer { lumberJackLogger := \u0026lumberjack.Logger{ Filename: \"./test.log\", MaxSize: 1, MaxBackups: 5, MaxAge: 30, Compress: false, } return zapcore.AddSync(lumberJackLogger) } func simpleHttpGet(url string) { sugarLogger.Debugf(\"Trying to hit GET request for %s\", url) resp, err := http.Get(url) if err != nil { sugarLogger.Errorf(\"Error fetching URL %s : Error = %s\", url, err) } else { sugarLogger.Infof(\"Success! statusCode = %s for URL %s\", resp.Status, url) resp.Body.Close() } } 执行上述代码，下面的内容会输出到文件——test.log中。 2019-10-27T15:50:32.944+0800 DEBUG logic/temp2.go:48 Trying to hit GET request for www.sogo.com 2019-10-27T15:50:32.944+0800 ERROR logic/temp2.go:51 Error fetching URL www.sogo.com : Error = Get www.sogo.com: unsupported protocol scheme \"\" 2019-10-27T15:50:32.944+0800 DEBUG logic/temp2.go:48 Trying to hit GET request for http://www.sogo.com 2019-10-27T15:50:33.165+0800 INFO logic/temp2.go:53 Success! statusCode = 200 OK for URL http://www.sogo.com 同时，可以在main函数中循环记录日志，测试日志文件是否会自动切割和归档（日志文件每1MB会切割并且在当前目录下最多保存5个备份）。 至此，我们总结了如何将Zap日志程序集成到Go应用程序项目中。 ","date":"2022-10-20","objectID":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/:4:3","tags":["go","日志","第三方库"],"title":"Zap日志库的使用","uri":"/posts/zap%E6%97%A5%E5%BF%97%E5%BA%93/"},{"categories":["运维"],"content":"Node Export 基于用户名密码访问","date":"2022-10-20","objectID":"/posts/%E4%B8%BAnodeexport%E9%85%8D%E7%BD%AE%E8%AE%BF%E9%97%AE%E5%AF%86%E7%A0%81/","tags":["监控","prometheus","exporter"],"title":"为NodeExport配置访问密码","uri":"/posts/%E4%B8%BAnodeexport%E9%85%8D%E7%BD%AE%E8%AE%BF%E9%97%AE%E5%AF%86%E7%A0%81/"},{"categories":["运维"],"content":"Export采集指标的地址谁都可以访问，这里可以通过添加基础认证的方式，使用用户名密码认证的方式去采集被监控端，提高安全性 ","date":"2022-10-20","objectID":"/posts/%E4%B8%BAnodeexport%E9%85%8D%E7%BD%AE%E8%AE%BF%E9%97%AE%E5%AF%86%E7%A0%81/:0:0","tags":["监控","prometheus","exporter"],"title":"为NodeExport配置访问密码","uri":"/posts/%E4%B8%BAnodeexport%E9%85%8D%E7%BD%AE%E8%AE%BF%E9%97%AE%E5%AF%86%E7%A0%81/"},{"categories":["运维"],"content":"配置被监控端 这个配置文件里面是要访问我暴露的指标需要的用户名密码。用户名和密码，密码是采用了一定的加密方式的，而不是写明文 生成密码 [root@localhost ~]# yum install httpd-tools –y 下面就是输入123456之后加密的密码，将这个密码保存在配置文件当中 [root@localhost ~]# htpasswd -nBC 12 '' | tr -d ':\\\\\\\\n' New password: Re-type new password: $2y$12$y4PaNc0UM0Jzi07jJf6zcuRFyp2GlH6F5rUKcE.xk3Aug2khcqa7m 修改其配置文件 [root@localhost node_exporter]# vim config.yml [root@localhost node_exporter]# cat config.yml basic_auth_users: prometheus: $2y$12$y4PaNc0UM0Jzi07jJf6zcuRFyp2GlH6F5rUKcE.xk3Aug2khcqa7m 现在让export引用这个配置文件 [root@localhost node_exporter]# vim /usr/lib/systemd/system/node_exporter.service ExecStart=/usr/local/node_exporter/node_exporter --web.config=/usr/local/node_exporter/config.yml [root@localhost node_exporter]# systemctl daemon-reload [root@localhost node_exporter]# systemctl restart node_exporter 输入prometheus加上密码123456 同时现在普罗米修斯没有配置，可以看到采集不了数据了 ","date":"2022-10-20","objectID":"/posts/%E4%B8%BAnodeexport%E9%85%8D%E7%BD%AE%E8%AE%BF%E9%97%AE%E5%AF%86%E7%A0%81/:1:0","tags":["监控","prometheus","exporter"],"title":"为NodeExport配置访问密码","uri":"/posts/%E4%B8%BAnodeexport%E9%85%8D%E7%BD%AE%E8%AE%BF%E9%97%AE%E5%AF%86%E7%A0%81/"},{"categories":["运维"],"content":"配置普罗米修斯 启用用户名密码访问 [root@localhost prometheus]# vim /usr/local/prometheus/prometheus.yml - job_name: 'webserver' basic_auth: username: prometheus password: 123456 static_configs: - targets: ['192.168.179.99:9100','192.168.179.102:9100'] [root@localhost prometheus]# ./promtool check config prometheus.yml Checking prometheus.yml SUCCESS: 0 rule files found 可以看到数据可以正常采集了 ","date":"2022-10-20","objectID":"/posts/%E4%B8%BAnodeexport%E9%85%8D%E7%BD%AE%E8%AE%BF%E9%97%AE%E5%AF%86%E7%A0%81/:2:0","tags":["监控","prometheus","exporter"],"title":"为NodeExport配置访问密码","uri":"/posts/%E4%B8%BAnodeexport%E9%85%8D%E7%BD%AE%E8%AE%BF%E9%97%AE%E5%AF%86%E7%A0%81/"},{"categories":["运维"],"content":"firewalld防火墙配置","date":"2022-10-20","objectID":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/","tags":["centos","防火墙"],"title":"防火墙配置","uri":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["运维"],"content":"服务配置 启动： systemctl start firewalld.service 查看状态： systemctl status firewalld.service 停止： systemctl disable firewalld.service 禁用： systemctl stop firewalld.service ","date":"2022-10-20","objectID":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:0:1","tags":["centos","防火墙"],"title":"防火墙配置","uri":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["运维"],"content":"三种策略 ACCEPT 允许 REJECT 拒绝 DROP 丢弃 ","date":"2022-10-20","objectID":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:0:2","tags":["centos","防火墙"],"title":"防火墙配置","uri":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["运维"],"content":"1. 查看 # 查看激活的域 firewall-cmd --get-active-zones # 查看开放的端口 firewall-cmd --zone=public --list-ports # 查看开放的服务 firewall-cmd --zone=public --list-services # 查看添加的规则 firewall-cmd --zone=public --list-rich-rules ","date":"2022-10-20","objectID":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:0:3","tags":["centos","防火墙"],"title":"防火墙配置","uri":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["运维"],"content":"2. 添加端口 ","date":"2022-10-20","objectID":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:0:4","tags":["centos","防火墙"],"title":"防火墙配置","uri":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["运维"],"content":"常用命令 #开放单个端口 firewall-cmd --zone=public --add-port=80/tcp --permanent # 开放端口范围 firewall-cmd --zone=public --add-port=8388-8389/tcp --permanent # 对 147.152.139.197 开放10000端口 firewall-cmd --permanent --add-rich-rule=\"rule family=\"ipv4\" source address=\"147.152.139.197/32\" port protocol=\"tcp\" port=\"10000\" accept\" # 拒绝端口： firewall-cmd --permanent --zone=public --add-rich-rule=' rule family=\"ipv4\" source address=\"47.52.39.197/32\" port protocol=\"tcp\" port=\"10000\" reject' # 开放全部端口给IP firewall-cmd --permanent --zone=public --add-rich-rule=' rule family=\"ipv4\" source address=\"192.168.0.1/32\" accept' # 开放全部端口给网段 firewall-cmd --permanent --zone=public --add-rich-rule=' rule family=\"ipv4\" source address=\"192.168.0.0/16\" accept' ","date":"2022-10-20","objectID":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:0:5","tags":["centos","防火墙"],"title":"防火墙配置","uri":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["运维"],"content":"3. 添加服务 # 查看全部支持的服务 firewall-cmd --get-service # 查看开放的服务 firewall-cmd --list-service # 添加服务,添加https firewall-cmd --add-service=https --permanent # 修改对应的配置文件是/etc/firewalld/zones/public.xml ","date":"2022-10-20","objectID":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:0:6","tags":["centos","防火墙"],"title":"防火墙配置","uri":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["运维"],"content":"4. 移除端口 # 移除添加的端口(其它的增加的策略也是将add改为remove即可) firewall-cmd --zone=public --remove-port=80/tcp --permanent ","date":"2022-10-20","objectID":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:0:7","tags":["centos","防火墙"],"title":"防火墙配置","uri":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["运维"],"content":"5. 重载配置 # 对路由规则进行修改后，需要重新加载规则才能使规则生效 firewall-cmd --reload ","date":"2022-10-20","objectID":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:0:8","tags":["centos","防火墙"],"title":"防火墙配置","uri":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["运维"],"content":"实战应用 ","date":"2022-10-20","objectID":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:0:9","tags":["centos","防火墙"],"title":"防火墙配置","uri":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["运维"],"content":"(1)限制ssh访问，仅允许白名单IP登录 也可以通过在/etc/host.deny里面配置来实现 # 取消默认开启的没有访问限制的ssh服务，让ssh服务默认情况下拒绝连接 firewall-cmd --permanent --remove-service=ssh # 允许特定ip或ip段访问22端口的ssh服务 firewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" port protocol=\"tcp\" port=\"22\" accept' # 重载firewall配置，使其生效 firewall-cmd --reload ","date":"2022-10-20","objectID":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:0:10","tags":["centos","防火墙"],"title":"防火墙配置","uri":"/posts/%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["开发"],"content":"go pretty库","date":"2022-10-19","objectID":"/posts/go-pretty/","tags":["go","第三方库"],"title":"Go Pretty","uri":"/posts/go-pretty/"},{"categories":["开发"],"content":"用于美化表格，列表，进度条，文本等的控制台输出 jedib0t/go-pretty: Table-writer and more in golang! (github.com) ","date":"2022-10-19","objectID":"/posts/go-pretty/:0:0","tags":["go","第三方库"],"title":"Go Pretty","uri":"/posts/go-pretty/"},{"categories":["开发"],"content":"table 可以在输出美化的表格 package main import ( \"os\" \"github.com/jedib0t/go-pretty/v6/table\" ) type Student struct { ID int Name string Age int School string } var students = []Student{ {ID: 1, Name: \"张三\", Age: 18, School: \"清华大学\"}, {ID: 2, Name: \"李四\", Age: 19, School: \"北京大学\"}, {ID: 3, Name: \"王五\", Age: 20, School: \"复旦大学\"}, {ID: 4, Name: \"赵六\", Age: 21, School: \"上海交通大学\"}, } func (s Student) toRow() table.Row { return table.Row{s.ID, s.Name, s.Age, s.School} } func main() { t := table.NewWriter() t.SetOutputMirror(os.Stdout) t.AppendHeader(table.Row{\"ID\", \"姓名\", \"年龄\", \"学校\"}) for _, s := range students { t.AppendRow(s.toRow()) } t.SetStyle(table.StyleColoredDark) t.Render() } 运行可以在终端中得到 Render同时也支持渲染html、csv等… ","date":"2022-10-19","objectID":"/posts/go-pretty/:1:0","tags":["go","第三方库"],"title":"Go Pretty","uri":"/posts/go-pretty/"}]